from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from dotenv import load_dotenv
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import os

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()


HF_LOCAL_DIR = "hf_model"  # ë¹Œë“œ ë•Œ ë°›ì•„ë‘” ìœ„ì¹˜
TOKENIZER_DIR = os.path.join(HF_LOCAL_DIR, "tokenizer")
MODEL_DIR = os.path.join(HF_LOCAL_DIR, "model")

# fast í† í¬ë‚˜ì´ì € (vocab.txt í•„ìš” ì—†ìŒ)
tokenizer = AutoTokenizer.from_pretrained(
    TOKENIZER_DIR,
    local_files_only=True,
)

# ëª¨ë¸ì€ ì €ë©”ëª¨ë¦¬ ì˜µì…˜ìœ¼ë¡œ ë¡œë“œ
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_DIR,
    local_files_only=True,
    low_cpu_mem_usage=True,
)

# CPU ë™ì  ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì ˆê°
model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

model.eval()
torch.set_grad_enabled(False)
torch.set_num_threads(1)  # CPU ìŠ¤ë ˆë“œ ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬/ì˜¤ë²„í—¤ë“œ ê°ì†Œ

device = torch.device("cpu")
model.to(device)

app = FastAPI()

class Request(BaseModel):
    text: str

@app.post("/predict")
def predict(request: Request):
    text = request.text.strip()

    inputs = model.tokenizer(
        text,
        return_tensors='pt',
        truncation=True,
        padding='max_length',
        max_length=150,
        return_attention_mask=True
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=-1)

    label = torch.argmax(probs, dim=-1).item()
    prob = probs[0][label].item()
    label_text = 'ì•…í”Œ' if label == 0 else 'ì¼ë°˜ ëŒ“ê¸€'

    # ğŸ”´ í™•ì‹ ë„ ê¸°ë°˜ ìƒ‰ìƒ ì •ì˜
    color = None
    if label == 0:  # ì•…í”Œë¡œ ì˜ˆì¸¡ëœ ê²½ìš°
        if prob >= 0.65:
            color = "red"
        elif prob >= 0.5:
            color = "orange"
        else:
            label_text = 'ì¼ë°˜ ëŒ“ê¸€'  # ì•…í”Œë¡œ ì˜ˆì¸¡ëì§€ë§Œ í™•ì‹  ë‚®ìŒ â†’ ì¼ë°˜ìœ¼ë¡œ ê°„ì£¼

    return {
        "text": text,
        "predicted_label": label,
        "label_name": label_text,
        "probability": round(prob, 4),
        "confidence_color": color
    }
# static ë””ë ‰í† ë¦¬ ì—°ê²°
app.mount("/static", StaticFiles(directory="static"), name="static")

# ë£¨íŠ¸ ê²½ë¡œì— index.html ë°˜í™˜
@app.get("/", response_class=HTMLResponse)
def read_index():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return f.read()
