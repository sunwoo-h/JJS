from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from dotenv import load_dotenv
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import os

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
HF_AUTH_TOKEN = os.getenv("HF_AUTH_TOKEN")

MODEL_NAME = "Junginn/kcelectra-toxic-comment-detector_V1"  # ì‹¤ì œ ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì •
TOKENIZER_NAME = "beomi/KcELECTRA-base"   # âœ… í† í¬ë‚˜ì´ì €ëŠ” ë² ì´ìŠ¤ì—ì„œ


tokenizer = AutoTokenizer.from_pretrained(
    TOKENIZER_NAME,
    token=HF_AUTH_TOKEN,       # use_auth_token ëŒ€ì‹ 
)


model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    token=HF_AUTH_TOKEN       # ë™ì¼í•˜ê²Œ token íŒŒë¼ë¯¸í„° ì‚¬ìš©
)
model.tokenizer = tokenizer  # infer í•¨ìˆ˜ì—ì„œ ì“°ê¸° ìœ„í•´
model.eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

app = FastAPI()

class Request(BaseModel):
    text: str

@app.post("/predict")
def predict(request: Request):
    text = request.text.strip()

    inputs = model.tokenizer(
        text,
        return_tensors='pt',
        truncation=True,
        padding='max_length',
        max_length=150,
        return_attention_mask=True
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=-1)

    label = torch.argmax(probs, dim=-1).item()
    prob = probs[0][label].item()
    label_text = 'ì•…í”Œ' if label == 0 else 'ì¼ë°˜ ëŒ“ê¸€'

    # ğŸ”´ í™•ì‹ ë„ ê¸°ë°˜ ìƒ‰ìƒ ì •ì˜
    color = None
    if label == 0:  # ì•…í”Œë¡œ ì˜ˆì¸¡ëœ ê²½ìš°
        if prob >= 0.65:
            color = "red"
        elif prob >= 0.5:
            color = "orange"
        else:
            label_text = 'ì¼ë°˜ ëŒ“ê¸€'  # ì•…í”Œë¡œ ì˜ˆì¸¡ëì§€ë§Œ í™•ì‹  ë‚®ìŒ â†’ ì¼ë°˜ìœ¼ë¡œ ê°„ì£¼

    return {
        "text": text,
        "predicted_label": label,
        "label_name": label_text,
        "probability": round(prob, 4),
        "confidence_color": color
    }
# static ë””ë ‰í† ë¦¬ ì—°ê²°
app.mount("/static", StaticFiles(directory="static"), name="static")

# ë£¨íŠ¸ ê²½ë¡œì— index.html ë°˜í™˜
@app.get("/", response_class=HTMLResponse)
def read_index():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return f.read()
